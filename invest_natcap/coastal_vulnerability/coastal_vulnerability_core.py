""" Coastal vulnerability model core functions """
import os
import re
import math
import numpy as np
import scipy as sp
from scipy.interpolate import LinearNDInterpolator as ip

from osgeo import gdal
from osgeo import ogr
from osgeo import osr

import logging
from invest_natcap import raster_utils

class NotAtSea(Exception): 
    """ Exception raised by cast_ray when the point for which to compute the
    fetch is not at sea """
    pass

LOGGER = logging.getLogger('coastal_vulnerability_core')
logging.basicConfig(format='%(asctime)s %(name)-15s %(levelname)-8s \
    %(message)s', level=logging.DEBUG, datefmt='%m/%d/%Y %H:%M:%S ')

def execute(args):
    """ Entry point for coastal vulnerability core
    
        For lots of debug output and data storage code, 
        check out revision 4318:705d54ae6c37

        args['foo'] - actual data structure the way I want them look like


        returns nothing"""

    pass

def sea():
    """ Return the code for a sea cell """
    return 0

def land():
    """ Return the code for a land cell """
    return 1

def nodata():
    """ Return the code for a nodata cell """
    return -1.0

def shore():
    """ Return the code for a shore cell """
    return 1

def is_sea(position, raster):
    """ Determine whether the cell is at sea or not.

        - position: current cell position
        - raster: array used to determine the cell value
                
        Returns True if the cell is at sea, False otrherwise."""
    return (raster[position[0], position[1]] == sea())

def is_land(position, raster):
    """ Determine whether the cell is on land or not. 

        - position: current cell position
        - raster: raster where the cell value is stored
                
        Returns True if the cell is at sea, False otrherwise."""
    return (raster[position[0], position[1]] == land())

def compute_vulnerability_index(r_geomorphology, r_relief, r_habitats, r_slr,
                                r_windexposure, r_waveexposure, r_surge):
    """ Main function that computes a coastal vulnerability index.
    
        r_geomorphology:
        r_relief:
        r_habitats:
        r_slr:
        r_windexposure:
        r_waveexposure:
        r_surge:
        
        returns something that is to be determined."""
    #vi = count_var = 6

    #r_windexposure = compute_wind_exposure(wind_wave_exposure_data_file, aoi, landmass)

    return math.sqrt(r_geomorphology * r_relief * r_habitats * r_slr *
                     r_windexposure * r_waveexposure * r_surge)

def set_H_threshold(threshold):
    """ Return 0 if fetch is strictly below a threshold in km, 1 otherwise.
    
        Inputs:
            fetch: fetch distance in meters.

        Return:
            1 if fetch >= threshold (in km)
            0 if fetch  < threshold

        Note: conforms to equation 4.8 in the invest documentation."""
    def H(fetch):
        return np.array(fetch >= (threshold * 1000)).astype(int)

    return H

def compute_wind_exposure(wind_data, aoi, landmass):
    """ Compute the wind exposure for every shore segment as in equation 4.5
    
        Inputs:
            - wind_data: wind information
            - aoi: used to set the raster extents
            - landmass: used to detect the shore
            
        Outputs:
            - A file called REI.tif that contains the wind exposure index along
              the shore
            - Intermediate files for each variable U, P, F for each sector."""
    # Variable initializations
    cell_size = 250                 # Cell size in meters
    max_fetch = 12500 / cell_size   # Maximum fetch in pixels
    
    sector_count = 16
    sector_range = range(sector_count)
    sectors_rad = np.array(sector_range, dtype=float) *2 *math.pi /sector_count
    sectors_deg = np.array(sector_range, dtype=int) *360 / sector_count

    basename = 'REI'
    extension = '.tif'  # Filename extension
   
    # Adjust the wind data to the aoi:
    wind_data = adjust_datapoints_to_aoi(wind_data, aoi)

    # Convert the landmass to the right projection (aoi's)
    reprojected_landmass_path = 'aoi_reprojected_landmass.shp'
    aoi_layer = aoi.GetLayer(0)
    destination_SR = aoi_layer.GetSpatialRef()
    reprojected_landmass = reproject_shape(landmass,
                            destination_SR, reprojected_landmass_path)

    # Extract the AOI and the landmasses as arrays
    aoi_array = array_from_shapefile(aoi, aoi, cell_size)
    land_array = array_from_shapefile(reprojected_landmass, aoi, cell_size)
    
    # Use the arrays to construct the shore data
    land_array[land_array == 0] = sea()
    land_array[aoi_array == 0] = nodata()

    # compute the fetch
    fetch = compute_fetch(land_array, sectors_rad, max_fetch)

    # Create a raster dict of the wind intensity U_n
    U = assign_dictionary(extract_REI_V(wind_data, aoi, cell_size))
    # Create a raster dict of the percent of all wind P_n in a given sector
    P = assign_dictionary(extract_REI_PCT(wind_data, aoi, cell_size))
    # Create a raster dict of the fetch distances F_n
    F = assign_dictionary(extract_fetch(fetch, aoi, cell_size))

    # Compute the REI
    REI = np.sum([U(n) *P(n) *F(n) for n in sectors_deg], axis=0)   
       
    # Save the result
    save_array(REI, basename + extension, aoi, cell_size)

def compute_wave_exposure(wave_data, aoi, landmass):
    """ Compute the wind exposure for every shore segment
    
        Inputs:
            - wave_data: wave information
            - aoi: used to set the raster extents
            - landmass: used to detect the shore
            
        Outputs:
            - A file called wave.tif that contains the wind exposure index along
              the shore
            - Intermediate files for each variable U, P, F for each sector."""
    # Variable initializations
    cell_size = 250                 # Cell size in meters
    max_fetch = 12500 / cell_size   # Maximum fetch in pixels
    
    sector_count = 16
    sector_range = range(sector_count)
    sectors_rad = np.array(sector_range, dtype=float) *2 *math.pi /sector_count
    sectors_deg = np.array(sector_range, dtype=int) *360 / sector_count

    basename = 'wave'
    extension = '.tif'  # Filename extension
   
    # Adjust the wind data to the aoi:
    wave_data = adjust_datapoints_to_aoi(wave_data, aoi)

    # Convert the landmass to the right projection (aoi's)
    reprojected_landmass_path = 'aoi_reprojected_landmass.shp'
    aoi_layer = aoi.GetLayer(0)
    destination_SR = aoi_layer.GetSpatialRef()
    reprojected_landmass = reproject_shape(landmass,
                            destination_SR, reprojected_landmass_path)

    # Extract the AOI and the landmasses as arrays
    aoi_array = array_from_shapefile(aoi, aoi, cell_size)
    land_array = array_from_shapefile(reprojected_landmass, aoi, cell_size)
    
    # Use the arrays to construct the shore data
    land_array[land_array == 0] = sea()
    land_array[aoi_array == 0] = nodata()

    # compute the fetch
    fetch = compute_fetch(land_array, sectors_rad, max_fetch)

    # Set H threshold, in km
    H = set_H_threshold(10)

    # Create a raster dict of the wind power intensity P_o(k)
    P_l = assign_dictionary(extract_REI_V(wave_data, aoi, cell_size))
    # Create a raster dict of the percent of all winds O_o(k) in a given sector
    O_l = assign_dictionary(extract_REI_PCT(wave_data, aoi, cell_size))
    # Create a raster dict of the wave power intensity P_l(k)
    P_o = assign_dictionary(extract_WavP(wave_data, aoi, cell_size))
    # Create a raster dict of the percent of all waves O_l(k) in a given sector
    O_o = assign_dictionary(extract_WavPPCT(wave_data, aoi, cell_size))
    # Create a raster dict of the fetch distances F(k)
    F = assign_dictionary(extract_fetch(fetch, aoi, cell_size))

    # Compute the oceanic wave exposure E_o
    E_o = np.sum([save_array(save_array(H(save_array(F(k), "fetch_" +str(k)
    +extension, aoi, cell_size)), 'H_' +str(k) +extension, aoi,
    cell_size) *P_o(k) *O_o(k), basename +'_' +str(k) \
    +extension, aoi, cell_size)  for k in sectors_deg], axis=0)   
       
    # Save the result
    save_array(E_o, "E_o" +extension, aoi, cell_size)

    # Compute the local wave exposure E_l
    E_l = np.sum([P_l(k) *O_l(k) for k in sectors_deg], axis=0)

    # Save the result
    save_array(E_l, "E_l" +extension, aoi, cell_size)

    # Compute the overall wave exposure
    E_w = np.amax([E_o, E_l], axis=0)

    # Save the result
    save_array(E_w, "E_w" +extension, aoi, cell_size)


def adjust_datapoints_to_aoi(data, aoi):
    """ Adjust the shapefile's data to the aoi, i.e. reproject and clip data
    points.
    
        Inputs:
            - data_file: shapefile name
            - aoi: area of interest
            
        Output:
            - A reprojected shapefile that is clipped to the aoi."""
    # Open the aoi and the datafile
    aoi_layer = aoi.GetLayer(0)
    destination_SR = aoi_layer.GetSpatialRef()

    data_layer = data.GetLayer(0)
     
    # Convert the datasource to the right projection (aoi's)
    reprojected_data_path = 'aoi_reprojected_data.shp'
    reprojected_data = reproject_shape(data,\
                        destination_SR, reprojected_data_path)
    # Clip all the shapes outside the aoi
    clipped_data_path = 'clipped_data.shp'
    clipped_data = clip_shape(reprojected_data, aoi, clipped_data_path)

    return clipped_data
    
def extract_WavP(wave_data, aoi, cell_size):
    """ Create dictionary of raster filenames of datum for each sector n.
    
        Inputs:
            - wave_data: wave data points adjusted to the aoi
            - aoi: used to create the rasters for each sector
            - cell_size: raster granularity in meters
            
        Output:
            A dictionary where keys are sector angles in degrees and values are
            raster filenames where U(n) is defined on each cell"""
    field_prefix = 'WavP_'
    extension = '.tif'

    return raster_list_from_interpolated_fields( \
        wave_data, field_prefix, extension, aoi, cell_size)

def extract_WavPPCT(wave_data, aoi, cell_size):
    """ Create dictionary of raster filenames of datum for each sector n.
    
        Inputs:
            - wave_data: wave data points adjusted to the aoi
            - aoi: used to create the rasters for each sector
            - cell_size: raster granularity in meters
            
        Output:
            A dictionary where keys are sector angles in degrees and values are
            raster filenames where U(n) is defined on each cell"""
    field_prefix = 'WavPPCT'
    extension = '.tif'

    return raster_list_from_interpolated_fields( \
        wave_data, field_prefix, extension, aoi, cell_size)

def extract_REI_V(wind_data, aoi, cell_size):
    """ Create dictionary of raster filenames of datum for each sector n.
    
        Inputs:
            - wind_data: wind data points adjusted to the aoi
            - aoi: used to create the rasters for each sector
            - cell_size: raster granularity in meters
            
        Output:
            A dictionary where keys are sector angles in degrees and values are
            raster filenames where U(n) is defined on each cell"""
    field_prefix = 'REI_V'
    extension = '.tif'

    return raster_list_from_interpolated_fields( \
        wind_data, field_prefix, extension, aoi, cell_size)

def extract_REI_PCT(wind_data, aoi, cell_size):
    """ Create dictionary of raster filenames of datum for each sector n.
    
        Inputs:
            - wind_data: wind data points adjusted to the aoi
            - aoi: used to create the rasters for each sector
            - cell_size: raster granularity in meters
            
        Output:
            A dictionary where keys are sector angles in degrees and values are
            raster filenames where P(n) is defined on each cell"""
    field_prefix = 'REI_PCT'
    extension = '.tif'

    return raster_list_from_interpolated_fields( \
        wind_data, field_prefix, extension, aoi, cell_size)

def raster_list_from_interpolated_fields(data, prefix, suffix, aoi, cell_size):
    """Interpolate user-specified data fields on rasters saved in a raster list
    
        Inputs:
            - data: the datasource
            - prefix: name used to find the fields
            - suffix: used to complete the filename. This is where the
              extension goes
            - aoi: used to set the raster size
            - cell_size: raster coarseness in meters
            
        Output:
            - A str:filename dictionary where the key is the remainder of the
              field name. If there is no remainder, then key == prefix"""
    # Get the datasource field
    layer = data.GetLayer(0)
    feature_definition = layer.GetLayerDefn()
    field_count = feature_definition.GetFieldCount()

    raster_list = {} # key is the direction angle

    for field in range(field_count):
        name = feature_definition.GetFieldDefn(field).GetNameRef()

        # Determine if the current field should be processed
        if re.match(prefix, name):
            name = name[len(prefix):]

            # Create raster
            separator = '_' if name else ''
            filename =  prefix +separator +name +suffix
            raster = raster_utils.create_raster_from_vector_extents(
                cell_size,cell_size, gdal.GDT_Float32, nodata(), filename, aoi)
            # Vectorize data
            raster_utils.vectorize_points(data, field, raster)
            # Store filename
            name = name if name else prefix
            raster_list[name] = filename

    return raster_list

def extract_fetch(fetch, aoi, cell_size):
    """ Create dictionary of raster filenames of fetch F(n) for each sector n.
    
        Inputs:
            - wind_data: wind data points adjusted to the aoi
            - aoi: used to create the rasters for each sector
            - cell_size: raster granularity in meters
            
        Output:
            A dictionary where keys are sector angles in degrees and values are
            raster filenames where F(n) is defined on each cell"""
    field_prefix = 'REI_fetch'
    extension = '.tif'

    # Save computed raster
    raster_list = {} # key is the direction angle

    # Extract the # of sectors, assumed to start at angle 0 with identical span
    sector_count = 0
    fetch_keys = fetch.keys()
    for point in fetch_keys:
        sector_count = len(fetch[point])
        break

    # Build F(n), raster filename dictionary and save data to disk
    for sector in range(sector_count):
        name = str(sector *360 /sector_count)

        # Open raster file
        filename = field_prefix +'_' +name +extension
        raster =\
            raster_utils.create_raster_from_vector_extents(cell_size,cell_size,\
            gdal.GDT_Float32, nodata(), filename, aoi)
        band = raster.GetRasterBand(1)
        array = band.ReadAsArray() 

        # Build a fetch array F(n) for sector n
        array = np.ones_like(array)
        for point in fetch_keys:
            array[point] = fetch[point][sector] * float(cell_size)

        # Save F(n) to disk
        band.WriteArray(array)

        raster_list[name] = filename

    return raster_list

def array_from_shapefile(shapefile, aoi, cell_size):
    """Burn shapes from a shapefile's first layer on an array.

        Inputs:
            - shapefile: the dataset to be discretized
            - cell_size: coarseness of the discretization (in meters)
        
        Output: An array where:
            - shapes are encoded as 1s
            - the rest is encoded as 0s"""
    raster_filename = 'tmp.tif'
    NO_DATA = 0
    raster = \
        raster_utils.create_raster_from_vector_extents(cell_size, cell_size,
        gdal.GDT_Int32, NO_DATA, raster_filename, aoi)
    band, NO_DATA = \
        raster_utils.extract_band_and_nodata(raster)
    band.Fill(NO_DATA)
    gdal.RasterizeLayer(raster, [1], shapefile.GetLayer(0), burn_values=[1])
    return band.ReadAsArray()

def save_array(array, filename, aoi, cell_size):
    """ Save an array to a raster constructed from an AOI.
    
        Inputs:
            - array: the array to be saved
            - filename: where the array will be saved
            - aoi: AOI used to create the raster
            - cell_size: granularity of the rasterization in meters
            
        Output:
            - save the array in a raster file constructed from the AOI and of
              granularity specified by cell_sizei
            - Return the array passed in so that further calls can be chained
              to the array"""
    try:
        raster =\
            raster_utils.create_raster_from_vector_extents(cell_size,cell_size, \
            gdal.GDT_Float32, nodata(), filename, aoi)
        band = raster.GetRasterBand(1)
        band.WriteArray(array)
    except:
       LOGGER.debug("Error: can't save array to %s." % filename) 

    return array

def assign_dictionary(dictionary):
    """ Closure that allows to index raster arrays from a file dictionary by string.
    
        Input: 
            - dictionary: the dictionary that points to raster files
            - sector: the key that points to an existing raster filename
            
        Output:
            - An array extracted from the raster file pointed to by the
              dictionary"""
    def raster_list(sector):
        raster_filename = dictionary[str(sector)]
        raster = gdal.Open(raster_filename)
        band = raster.GetRasterBand(1)
        raster_array = band.ReadAsArray()
        
        raster = None
        band = None
        
        return raster_array

    return raster_list


def reproject_shape(shape_to_reproject, target_sr, output_path):
    """Changes the projection of a shapefile by creating a new shapefile 
    based on the projection passed in.  The new shapefile then copies all the 
    features and fields of the shapefile to reproject as its own. 
    The reprojected shapefile is written to 'outputpath' and is returned.
    
    shape_to_reproject - A shapefile to be copied and reprojected.
    target_sr - The desired projection as a SpatialReference from a WKT string.
    output_path - The path to where the new shapefile should be written to disk.
    
    returns - The reprojected shapefile.
    """
    shape_source = output_path
    #If this file already exists, then remove it
    if os.path.isfile(shape_source):
        os.remove(shape_source)
    #Get the layer of points from the current point geometry shape
    in_layer = shape_to_reproject.GetLayer(0)
    #Get the layer definition which holds needed attribute values
    in_defn = in_layer.GetLayerDefn()
    #Create a new shapefile with similar properties of the current 
    #point geometry shape
    shp_driver = ogr.GetDriverByName('ESRI Shapefile')
    shp_ds = shp_driver.CreateDataSource(shape_source)
    #Create the new layer for the shapefile using same name and geometry
    #type from shape_to_reproject, but different projection
    shp_layer = shp_ds.CreateLayer(in_defn.GetName(), target_sr, \
                                   in_defn.GetGeomType())
    #Get the number of fields in the current point shapefile
    in_field_count = in_defn.GetFieldCount()
    #For every field, create a duplicate field and add it to the new 
    #shapefiles layer
    for fld_index in range(in_field_count):
        src_fd = in_defn.GetFieldDefn(fld_index)
        fd_def = ogr.FieldDefn(src_fd.GetName(), src_fd.GetType())
        fd_def.SetWidth(src_fd.GetWidth())
        fd_def.SetPrecision(src_fd.GetPrecision())
        shp_layer.CreateField(fd_def)

    in_layer.ResetReading()
    #Get the spatial reference of the source layer to use in transforming
    source_sr = in_layer.GetSpatialRef()
    #Create a coordinate transformation
    coord_trans = osr.CoordinateTransformation(source_sr, target_sr)
    #Get the first feature from the shapefile
    in_feat = in_layer.GetNextFeature()
    #Copy all of the features in shape_to_reproject to the new shapefile
    while in_feat is not None:
        geom = in_feat.GetGeometryRef()
        #Transform the geometry into a format desired for the new projection
        geom.Transform(coord_trans)
        #Copy shape_to_reproject's feature and set as new shapes feature
        out_feat = ogr.Feature(feature_def=shp_layer.GetLayerDefn())
        out_feat.SetFrom(in_feat)
        out_feat.SetGeometry(geom)
        #For all the fields in the feature set the field values from the 
        #source field
        for fld_index2 in range(out_feat.GetFieldCount()):
            src_field = in_feat.GetField(fld_index2)
            out_feat.SetField(fld_index2, src_field)

        shp_layer.CreateFeature(out_feat)
        out_feat.Destroy()

        in_feat.Destroy()
        in_feat = in_layer.GetNextFeature()

    return shp_ds

def clip_shape(shape_to_clip, binding_shape, output_path):
    """Copies a polygon or point geometry shapefile, only keeping the features
    that intersect or are within a binding polygon shape.

    Code directly copied from Doug's Wave Energy model.
    
    shape_to_clip - A point or polygon shapefile to clip
    binding_shape - A polygon shapefile indicating the bounds for the
                    shape_to_clip features
    output_path  - The path for the clipped output shapefile
    
    returns - A shapefile representing the clipped version of shape_to_clip
    """
    shape_source = output_path
    #If the output_path is already a file, remove it
    if os.path.isfile(shape_source):
        os.remove(shape_source)
    #Get the layer of points from the current point geometry shape
    in_layer = shape_to_clip.GetLayer(0)
    #Get the layer definition which holds needed attribute values
    in_defn = in_layer.GetLayerDefn()
    #Get the layer of the polygon (binding) geometry shape
    clip_layer = binding_shape.GetLayer(0)
    #Create a new shapefile with similar properties of the 
    #current point geometry shape
    shp_driver = ogr.GetDriverByName('ESRI Shapefile')
    shp_ds = shp_driver.CreateDataSource(shape_source)
    shp_layer = shp_ds.CreateLayer(in_defn.GetName(), in_layer.GetSpatialRef(), 
                                   in_defn.GetGeomType())
    #Get the number of fields in the current point shapefile
    in_field_count = in_defn.GetFieldCount()
    #For every field, create a duplicate field and add it to the 
    #new shapefiles layer
    for fld_index in range(in_field_count):
        src_fd = in_defn.GetFieldDefn(fld_index)
        fd_def = ogr.FieldDefn(src_fd.GetName(), src_fd.GetType())
        fd_def.SetWidth(src_fd.GetWidth())
        fd_def.SetPrecision(src_fd.GetPrecision())
        shp_layer.CreateField(fd_def)
    LOGGER.debug('Binding Shapes Feature Count : %s', 
                 clip_layer.GetFeatureCount())
    LOGGER.debug('Shape to be Bounds Feature Count : %s', 
                 in_layer.GetFeatureCount())
    #Retrieve all the binding polygon features and save their cloned 
    #geometry references to a list
    clip_feat = clip_layer.GetNextFeature()
    clip_geom_list = []
    while clip_feat is not None:
        clip_geom = clip_feat.GetGeometryRef()
        #Get the spatial reference of the geometry to use in transforming
        source_sr = clip_geom.GetSpatialReference()
        #Retrieve the current point shapes feature and get it's 
        #geometry reference
        in_layer.ResetReading()
        in_feat = in_layer.GetNextFeature()
        geom = in_feat.GetGeometryRef()
        #Get the spatial reference of the geometry to use in transforming
        target_sr = geom.GetSpatialReference()
        #Create a coordinate transformation
        coord_trans = osr.CoordinateTransformation(source_sr, target_sr)
        #Transform the polygon geometry into the same format as the 
        #point shape geometry
        clip_geom.Transform(coord_trans)
        #Add geometry to list
        clip_geom_list.append(clip_geom.Clone())
        in_feat.Destroy()
        clip_feat.Destroy()
        clip_feat = clip_layer.GetNextFeature()

    in_layer.ResetReading()
    in_feat = in_layer.GetNextFeature()
    #For all the features in the current point shape (for all the points)
    #Check to see if they Intersect with any of the binding polygons geometry 
    #and if they do, copy that point and it's fields to the new shape
    while in_feat is not None:
        #Check to see if the point falls in any of the polygons
        for clip_geom in clip_geom_list:
            geom = in_feat.GetGeometryRef()
            #Intersection returns a new geometry if they intersect, null
            #otherwise.
            geom = geom.Intersection(clip_geom)
            if(geom.GetGeometryCount() + geom.GetPointCount()) != 0:
                #Create a new feature from the input feature and set 
                #its geometry
                out_feat = ogr.Feature(feature_def=shp_layer.GetLayerDefn())
                out_feat.SetFrom(in_feat)
                out_feat.SetGeometryDirectly(geom)
                #For all the fields in the feature set the field values from 
                #the source field
                for fld_index2 in range(out_feat.GetFieldCount()):
                    src_field = in_feat.GetField(fld_index2)
                    out_feat.SetField(fld_index2, src_field)
    
                shp_layer.CreateFeature(out_feat)
                out_feat.Destroy()
                break
            
        in_feat.Destroy()
        in_feat = in_layer.GetNextFeature()

    return shp_ds

def convert_shape_to_array(shapefile, aoi, cell_size):
    """ Convert a shapefile to an array.
    
        - shapefile: location of the shapefile to be rasterized
        - aoi: location of the shapefile containing the area of interest
        - cell_size: granularity of the rasterization
        
        Returns an array with cell codes for land(), sea(), and nodata()."""
    # Try to open the area of interest:
    try:
        with open(aoi): 
            pass        
    except IOError:
        print("File ", aoi, " doesn't exist...")

    # Try to open the shapefile:
    try:
        with open(shapefile): 
            pass        
    except IOError:
        print("File ", shapefile, " doesn't exist...")

    # Open the shapefiles, and extract the shapes from the first layers
    aoi_datasource = ogr.Open(aoi)
    global_datasource = ogr.Open(shapefile)

    aoi_layer = aoi_datasource.GetLayer(0)
    global_layer = global_datasource.GetLayer(0)

    aoi_raster_filename = 'aoi_raster.tif'
    global_raster_filename = 'global_raster.tif'

    aoi_raster = \
        raster_utils.create_raster_from_vector_extents(cell_size, cell_size,
        gdal.GDT_Int32, nodata(), aoi_raster_filename, aoi_datasource)

    global_dataset = raster_utils.new_raster_from_base(aoi_raster, 
        global_raster_filename, 'GTiff', nodata(), gdal.GDT_Int32)

    
    # Get the band and nodata for each file
    aoi_band, aoi_nodata = \
        raster_utils.extract_band_and_nodata(aoi_raster)

    global_band, global_nodata = \
        raster_utils.extract_band_and_nodata(global_dataset)

    # Initialize the band and burn the shapefile on it for each file
    aoi_band.Fill(aoi_nodata)
    gdal.RasterizeLayer(aoi_raster, [1], aoi_layer, burn_values=[land()])

    global_band.Fill(global_nodata)
    gdal.RasterizeLayer(global_dataset,[1], global_layer, burn_values=[land()])

    # Extract the array from the bands
    aoi_array = aoi_band.ReadAsArray()
    global_array = global_band.ReadAsArray()

    # Initialize the raster with land, sea, and nodata cells
    landmass_array = np.ones_like(global_array) * land()
    landmass_array[global_array == global_nodata] = sea()
    landmass_array[aoi_array == aoi_nodata] = nodata()

    # cleanup before returning
    aoi_datasource = None
    global_datasource = None
    
    return landmass_array

def small_distance(path, d_max):
    """ Determines if the path is within the threshold minus an epsilon.
    
        Inputs:
        - path: coordinates used to compute the distance.
        - d_max: distance threshold.
        
        Returns False if pathlength is clearly above the distance threshold 
        (up to an epsilon)."""
    return (np.sqrt(np.sum(np.square(path))) <(d_max+0.0001))

def should_step(origin, path, d_max, raster):
    """ Returns true if the cast_ray algorithm should continue stepping.
    
        Inputs:
        - origin, path: coordinates used to get the raster position
        - d_max: maximum fetch distance
        - raster: geographic data to work with
        
        Returns True if cell is sea, within maximum fetch distance, 
        and within raster boundaries. """
    sea = False
    valid_index = (min(np.around(origin + path)) >= 0)

    try:
        sea = is_sea(np.around(origin + path), raster)
    except:
        return False

    return valid_index and sea and small_distance(path, d_max)

def cast_ray(origin, direction, d_max, raster):
    """ March from the origin towards a direction until either land or a
    maximum distance is met.
    
        Inputs:
        - origin: algorithm's starting point -- has to be on sea
        - direction: marching direction
        - d_max: maximum distance to traverse
        - raster: land mass raster
        
        Returns the distance to the origin."""
    # Initialize the origin, step and path
    O = np.around(np.array(list(origin)))
    unit_step = direction / np.fabs(direction).max()
    path = np.array([0., 0.])

    # Not on sea, no fetch
    if not is_sea(origin, raster): 
        raise NotAtSea('Not at sea, no fetch')

    # Short distance, no fetch
    if (d_max < 1.0): 
        return 0.0

    # Preliminary checks
    assert raster.size > 1      # More than 1 point
    assert(np.fabs(direction).max() > 0) # Non-zero vector

    # Step until we can't, then backtrack once
    while should_step(O, path, d_max, raster): 
        path += unit_step
    path -= unit_step

    return np.sqrt(np.sum(np.square(path)))
   
def compute_fetch(land_raster, directions, d_max):
    """ Given a land raster, return the fetch distance from a point
    in given directions 
        
        - land_raster: raster where land is encoded as 1s, sea as 0s,
            and cells outside the area of interest as anything 
            different from 0s or 1s.
        - directions: tuple of angles (in radians) from which the fetch
            will be computed for each pixel.
        - d_max: maximum distance over which to compute the fetch
                
        
        returns:dictionary of fetch data where the key is a shore point
                coordinates, and the value is a tuple (same size as directions) 
                containing fetch distances from that point."""
    # Extract shore from raster
    shore_raster = detect_shore(land_raster)
    shore_points = np.where(shore_raster == shore())

    assert(len(shore_points[0]) > 0)
    
    # precompute directions
    direction_vectors = np.empty((len(directions), 2))

    # Raster convention: -Up is north, i.e. decreasing 'i' is towards north,
    #                       hence the minus sign in front of the cos in
    #                       direction_vectors
    # Wind convention: Wind is defined as blowing FROM and not TOWARDS. This
    #                  means that winds blowing from sector n are oriented
    #                  towards direction n + 180, wnich is the fetch direction
    for d in range(len(directions)):
        direction_vectors[d] = (round(-math.cos(directions[d]+math.pi), 10),\
                                round( math.sin(directions[d]+math.pi), 10))
#        print("direction_vectors[", d,"]=",direction_vectors[d])
    fetch = {}

    # Compute fetch for each point (i, j)
    for point in zip(shore_points[0], shore_points[1]):
        try:
            fetch[point] = ()
            for direction in direction_vectors:
                d = cast_ray(point, direction, d_max, land_raster)
                fetch[point] = fetch[point] + (d,)
        except NotAtSea:
            del(fetch[point])

    return fetch

def detect_shore(raster):
    """ Extract the boundary between land and sea from a raster.
    
        - raster: numpy array with sea, land and nodata values.
        
        returns a numpy array the same size as the input raster with the shore
        encoded as ones, and zeros everywhere else."""
    # Rich's super-short solution, which uses convolution.
    # Works if land, sea, and nodata have different values:
    assert(land()   != sea())
    assert(sea()    != nodata())
    assert(nodata() != land())

    kernel = np.array([[-1, -1, -1],
                       [-1,  8, -1],
                       [-1, -1, -1]])

    # Generate the nodata shore artifacts
    aoi = np.ones_like(raster) * sea()
    aoi[raster == nodata()] = nodata()

    negative_borders = (sp.signal.convolve2d(aoi, \
                                            kernel, \
                                            mode='same') <0 ).astype('int')

    # Generate the real borders (including data artifacts)
    borders = (sp.signal.convolve2d(raster, \
                                 kernel, \
                                 mode='same') <0 ).astype('int')
    
    # Useful borders = all borders - borders from nodata
    borders = ((borders - negative_borders) >0 ).astype('int') * shore()

    return borders
 
