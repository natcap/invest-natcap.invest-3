from __future__ import print_function

import unittest
import logging
import os
import sys
import subprocess
import math
import numpy as np
import random
import time
import csv
import glob
import cProfile

from osgeo import gdal
from osgeo import ogr
from nose.plugins.skip import SkipTest

import invest_test_core
from invest_natcap import raster_utils
from invest_natcap.coastal_vulnerability \
    import coastal_vulnerability as cv
from invest_natcap.coastal_vulnerability \
    import coastal_vulnerability_core as cvc


LOGGER = logging.getLogger('coastal_vulnerability_test')
logging.basicConfig(format='%(asctime)s %(name)-15s %(levelname)-8s \
    %(message)s', level=logging.DEBUG, datefmt='%m/%d/%Y %H:%M:%S ')

class TestCoastalVulnerability(unittest.TestCase):
    """Main testing class for the coastal vulnerability tests"""
    
    def make_input_data(self):
        args = {}

        args['execution_mode'] = 'generate all data'
        #args['execution_mode'] = 'fast'
        args['area_computed'] = 'both' 
        #args['area_computed'] = 'sheltered' 
        args['workspace_dir'] = \
        u'data/test_out/coastal_vulnerability/'
        args['output_base_directory'] = \
        u'data/test_out/coastal_vulnerability/'
        args['aoi_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/AOI_BarkClay.shp')
        #u'../../coastal_vulnerability_test_data/AOI_MB.shp')
        #u'../../coastal_vulnerability_test_data/FL_AOI.shp')
        args['landmass_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/global_polygon.shp')
        args['population_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/global_pop/w001001.adf')
        args['climatic_forcing_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/global_WaveWatchIII.shp')
        #u'../../coastal_vulnerability_test_data/WaveWatchIII_MB.shp')
        args['bathymetry_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/claybark_dem/hdr.adf')
        #u'../../coastal_vulnerability_test_data/dem_MB/w001001.adf')
        args['geomorphology_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/Geomorphology_WCVI.shp')
        #u'../../coastal_vulnerability_test_data/Geomorphology_MB.shp')
        args['relief_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/claybark_dem/hdr.adf')
        args['habitats_csv_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/NaturalHabitats_WCVI.csv')
        args['habitats_directory_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/NaturalHabitats_WCVI')
        #u'../../coastal_vulnerability_test_data/NaturalHabitats_MB')
        args['surge_potential_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/claybark_dem/hdr.adf')
        args['continental_shelf_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/global_continentalShelf.shp')
        args['sea_level_rise_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/SLR_WCVI.shp')
        args['additional_layer_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/SLR_WCVI.shp')
        args['structures_uri'] = os.path.join(args['workspace_dir'], \
        u'../../coastal_vulnerability_test_data/Structures_WCVI.shp')

        args['climatic_forcing_constant'] = "5"
        args['bathymetry_constant'] = "5"
        args['elevation_averaging_radius'] = 5000
        args['relief_constant'] = "5"
        args['geomorphology_constant'] = "5"
        args['habitats_constant'] = "5"
        args['surge_potential_constant'] = "5"
        args['sea_level_rise_constant'] = "5"
        args['additional_layer_constant'] = "5"
        args['structures_constant'] = "5"

        args['mean_sea_level_datum'] = 0
        args['depth_contour'] = 150
        args['cell_size'] = 250       # cell size in meters
        args['exposure_proportion'] = 0.8   # Used to differentiate between
                                            # sheltered and exposed shoreline
        args['max_fetch'] = 12000      # max fetch in meters
        args['rays_per_sector'] = 1    # number of rays in sectors
        args['H_threshold'] = 12000     # H threshold in km as specified in 
                                        # equ 4.8 in the user guide
        args['depth_threshold'] = 10
        args['spread_radius'] = 250    # spread in meters
        args['urban_center_threshold'] = 5000   # for the urban vulnerability 
                                                # histogram
        args['population_radius'] = 1000    # radius in meters within which the
                                            # population size is assessed.
        # Preliminary tests...
        assert(os.path.isdir(args['workspace_dir']))
        print('cwd', os.getcwd())
        print('aoi', args['aoi_uri'])
        URIs = [key for key in args.keys() if '_uri' in key]
        for uri in URIs:
            assert os.path.exists(args[uri]), 'Missing ' + args[uri] 

        return args

    def setUp(self):
        """ Set up a test coastline on which to use the marching square
        algorithm 
        
            - inputs: none (hard-coded coastline, hard-coded ray directions)
            - output: an array of (type?) 2-tuples (direction, length)
        """
        print('Generating input data...')
        self.args = self.make_input_data()
        self.args['regression_data_directory'] = \
        os.path.join(self.args['workspace_dir'], \
        '../../coastal_vulnerability_regression_data').encode('utf-8')
        self.args['intermediate_directory'] = \
            os.path.join(self.args['workspace_dir'], \
            'intermediate').encode('utf-8')
        self.args['outputs_directory'] = \
            os.path.join(self.args['workspace_dir'], 'outputs').encode('utf-8')
        self.args['aoi_uri'] = self.args['aoi_uri'].encode('utf-8')

    def test_output_area(self):
        """ The user can specify the shore area over which to compute 
        the output: either over the sheltered segments, or over all the 
        segments. Testing that the area over which to compute the output is
        consistent with the option chosen by the user.
            
            Inputs:

            Outputs:
                None.
        """
        # Load the fetch regression data
        distances_uri = os.path.join(self.args['regression_data_directory'], \
            'distances.csv')
        depths_uri = os.path.join(self.args['regression_data_directory'], \
            'depths.csv')
        regression_distances = {}
        regression_depths = {}
        with open(distances_uri, 'rb') as distances:
            reader = csv.reader(distances)
            for entry in reader:
                key = tuple(map(float, entry[0][1:-1].split(',')))
                entry[1] = map(float,entry[1][1:-1].replace('\n','').split())
                value = np.array(entry[1])
                regression_distances[key] = value
        with open(depths_uri, 'rb') as depths:
            reader = csv.reader(depths)
            for entry in reader:
                key = tuple(map(float, entry[0][1:-1].split(',')))
                entry[1] = map(float,entry[1][1:-1].replace('\n','').split())
                value = np.array(entry[1])
                regression_depths[key] = value
        args = {}
        args['intermediate_directory'] = self.args['intermediate_directory']
        args['outputs_directory'] = self.args['outputs_directory']
        args['aoi_uri'] = self.args['aoi_uri']
        args['shore_uri'] = self.args['shore_uri']
        args['sector_count'] = self.args['sector_count']
        args['exposure_proportion'] = self.args['exposure_proportion']
        args['max_fetch'] = 20000
        args['cell_size'] = 250
        args['depth_threshold'] = 50
        args['fetch_distances'] = regression_distances
        args['fetch_depths'] = regression_depths
        args['prefix'] = 'test'
        # First option: compute over all the shoreline segments
        args['area_computed'] = 'both'
        # Run the computation        
        data_uri = cvc.compute_segment_exposure(args) 
        # Extract the computed and regression data for comparison
        computed_dataset = gdal.Open(data_uri['shore_uri'])
        regression_dataset=os.path.join(self.args['regression_data_directory'],\
            'shore_of_interest_both.tif')
        # Assert if computed and regression data differ
        invest_test_core.assertTwoDatasetEqualURI(self, computed_dataset, \
            regression_dataset)
        # Second option: compute over the sheltered shoreline segments only
        args['area_computed'] = 'sheltered'
        # Run the computation
        data_uri = cvc.compute_segment_exposure(args) 
        # Extract the computed and regression data for comparison
        computed_dataset = gdal.Open(data_uri['shore_uri'])
        regression_dataset=os.path.join(self.args['regression_data_directory'],\
            'shore_of_interest_sheltered.tif')
        # Assert if computed and regression data differ
        invest_test_core.assertTwoDatasetEqualURI(self, computed_dataset, \
            regression_dataset)

        assert(False)

    def test_compute_structure_protection(self):
        args = {}
        args['aoi_uri'] = self.args['aoi_uri'].encode('utf-8')
        args['shore_uri'] = self.args['shore_uri'].encode('utf-8')
        args['structures_uri'] = self.args['structures_uri'].encode('utf-8')
        args['cell_size'] = 250
        args['intermediate_directory'] = self.args['intermediate_directory']
        args['prefix'] = 'test'
        # Run the computation        
        data_uri = cvc.compute_structure_protection(args) 
        # Extract the computed and regression data for comparison
        computed_dataset = data_uri['structure_edges'].encode('utf-8')
        regression_dataset=os.path.join(self.args['regression_data_directory'],\
            'structure_edges.tif').encode('utf-8')
        # Assert if computed and regression data differ
        invest_test_core.assertTwoDatasetEqualURI(self, computed_dataset, \
            regression_dataset)

    def test_compute_segment_exposure(self):
        # Load the fetch regression data
        distances_uri = os.path.join(self.args['regression_data_directory'], \
            'distances.csv')
        depths_uri = os.path.join(self.args['regression_data_directory'], \
            'depths.csv')
        regression_distances = {}
        regression_depths = {}
        #with open(distances_uri, 'rb') as distances:
        #    reader = csv.reader(distances)
        #    for entry in reader:
        #        key = tuple(map(float, entry[0][1:-1].split(',')))
        #        entry[1] = map(float,entry[1][1:-1].replace('\n','').split())
        #        value = np.array(entry[1])
        #        regression_distances[key] = value
        #with open(depths_uri, 'rb') as depths:
        #    reader = csv.reader(depths)
        #    for entry in reader:
        #        key = tuple(map(float, entry[0][1:-1].split(',')))
        #        entry[1] = map(float,entry[1][1:-1].replace('\n','').split())
        #        value = np.array(entry[1])
        #        regression_depths[key] = value
        args = {}
        args['area_computed'] = self.args['area_computed']
        args['intermediate_directory'] = self.args['intermediate_directory']
        args['outputs_directory'] = self.args['outputs_directory']
        args['aoi_uri'] = self.args['aoi_uri']
        args['shore_uri'] = self.args['shore_uri']
        args['sector_count'] = self.args['sector_count']
        args['exposure_proportion'] = self.args['exposure_proportion']
        args['max_fetch'] = 20000
        args['cell_size'] = 250
        args['depth_threshold'] = 30
        args['prefix'] = 'test-'
        sector_range = range(args['sector_count'])
        sectors_rad = np.array(sector_range, dtype=float) *2 *math.pi / \
            args['sector_count']
        landmass_uri = os.path.join(self.args['regression_data_directory'], \
            'landmass.tif')
        land_raster = gdal.Open(landmass_uri)
        land_array = land_raster.GetRasterBand(1).ReadAsArray()
        shore_raster = gdal.Open(args['shore_uri'])
        shore_array = shore_raster.GetRasterBand(1).ReadAsArray()
        bathymetry_uri = os.path.join(self.args['regression_data_directory'], \
            'bathymetry.tif')
        bathymetry_raster = gdal.Open(bathymetry_uri)
        bathymetry_array = bathymetry_raster.GetRasterBand(1).ReadAsArray()
        regression_distances, regression_depths = \
            cvc.compute_fetch_fast(land_array, sectors_rad, \
            args['max_fetch']/args['cell_size'], shore_array, bathymetry_array)

        args['fetch_distances'] = regression_distances
        args['fetch_depths'] = regression_depths
        # Run the computation
        data_uri = cvc.compute_segment_exposure(args)
        # Extract the computed and regression data for comparison
        #computed_dataset = os.path.join(self.args['regression_data_directory'],\
        #    '1_a-shore_exposure.tif')
        computed_dataset = data_uri['shore_exposure']
        regression_dataset=os.path.join(self.args['regression_data_directory'],\
            'shore_exposure.tif')
        # Assert if computed and regression data differ
        invest_test_core.assertTwoDatasetEqualURI(self, computed_dataset, \
            regression_dataset)

    def validate_with_regression_data(self, regression_dir, data_dir):
        """ Compare regression files to their countreparts in data_dir.
            The algorithm tests all '.tif' and '.csv' files in regression_dir
            and compares them to their homologues in data_dir. Once all files
            are validated, the algorithm proceeds to the sub-directories in 
            a depth-first search.
            
            Inputs:
                -regression_dir: URI to the parent directory that contains the
                regression data. Only .tif and .csv files and subdirectories 
                in this directory will be checked in data_dir.
                -data_dir: the data directory against which the regression
                files should be tested against.
                
            Returns 'True' if all regression tests pass, False otherwise."""
        assert os.path.isdir(regression_dir), \
            "regression subdirectory '" + regression_dir + "' doesn't exist"
        assert os.path.isdir(data_dir), \
            "data subdirectory '" + data_dir + "' doesn't exist" 
        
        test_passed = True
        # Find all the files and directories in the regression and data
        # directories
        regr_path = regression_dir.encode('utf-8')
        regr_dirs = [d.encode('utf-8') for d in os.listdir(regr_path) if
            os.path.isdir(os.path.join(regr_path,d))]
        regr_files = [f.encode('utf-8') for f in os.listdir(regr_path) if
            os.path.isfile(os.path.join(regr_path, f))]
        data_path = data_dir.encode('utf-8')
        data_dirs = [d.encode('utf-8') for d in os.listdir(data_path) if
            os.path.isdir(os.path.join(data_path, d))]
        data_files = [f.encode('utf-8') for f in os.listdir(data_path) if
            os.path.isfile(os.path.join(regr_path, f))]

        # Check that all regression directories exist in the data to be 
        # tested
        regr_dirs_set = set(regr_dirs)
        data_dirs_set = set(data_dirs)
        missing_directories = regr_dirs_set - data_dirs_set
        message = 'Missing directories ' + str(missing_directories)
        assert not missing_directories, message

        # Check that all files exist in the data to be tested
        regr_files_set = set(regr_files)
        data_files_set = set(data_files)
        missing_files = regr_files_set - data_files_set
        message = 'Missing files: '+str(missing_files)+' in "'+data_path+'"'
        assert not missing_files, message

        # Separate .tif from .csv files 
        tif_regr_files = [f for f in regr_files if '.tif' in f]
        csv_regr_files = [f for f in regr_files if '.csv' in f]

        # Sort the files alphabetically
        tif_regr_files.sort()
        # Test tifs:
        for tif_file in tif_regr_files:
            regr_uri = os.path.join(regr_path, tif_file)
            data_uri = os.path.join(data_path, tif_file)
            invest_test_core.assertTwoDatasetEqualURI(self, regr_uri, data_uri)
                
        # Sort the files alphabetically
        csv_regr_files.sort()
        # Test CSVs:
        for csv_file in csv_regr_files:
            regr_uri = os.path.join(regr_path, csv_file)
            data_uri = os.path.join(data_path, csv_file)
            invest_test_core.assertTwoCSVEqualURI(self, regr_uri, data_uri)

        for sub_dir in regr_dirs:
            regr_subdirectory = os.path.join(regr_path, sub_dir) 
            data_subdirectory = os.path.join(data_path, sub_dir)
            
            test_passed &= \
            self.validate_with_regression_data(regr_subdirectory, data_subdirectory)
        return test_passed

    def test_execute(self):
        # ---- debug test!
        #raster = raster_utils.create_raster_from_vector_extents( \
        #250, 250, gdal.GDT_Float32, 0., os.path.join( \
        #self.args['intermediate_directory'].encode('utf-8'), 'test_raster.tif'), \
        #ogr.Open(self.args['aoi_uri'].encode('utf-8')))
        #raster_utils.vectorize_points( \
        #ogr.Open(self.args['climatic_forcing_uri'].encode('utf-8')), 'REI_V', raster)
        base_wd = os.getcwd()
        cvc.preprocess_inputs(self.args)
        cvc.execute(self.args)

        # Compare output rasters with regression data
        regression_dir = os.path.join(self.args['regression_data_directory'], \
            'intermediate_regression_data')
        data_dir = os.path.join(self.args['workspace_dir'], 'intermediate')
        self.validate_with_regression_data(regression_dir, data_dir)
        regression_dir = os.path.join(self.args['regression_data_directory'], \
            'outputs_regression_data')
        data_dir = os.path.join(self.args['workspace_dir'], 'outputs')
        self.validate_with_regression_data(regression_dir, data_dir)
    
    # TODO: use adjusted_ranks when it will be accessible...
    # TODO: test limit cases
    def test_adjust_layer_ranks(self):
        one_value = np.array([[5,5,0],[5,5,0]])
        adjusted_value = cvc.adjust_layer_ranks(one_value)
        unique_value = np.unique(adjusted_value)
        assert( (unique_value.size == 2) and \
                (unique_value[0] == 0) and \
                (unique_value[1] == 3))

        two_values = np.array([[3,1,0],[3,1,0]])
        adjusted_value = cvc.adjust_layer_ranks(two_values)
        unique_value = np.unique(adjusted_value)
        assert( (unique_value.size == 3) and \
                (unique_value[0] == 0) and \
                (unique_value[1] == 3) and \
                (unique_value[2] == 4))
    
        three_values = np.array([[5,1,0],[1,2,0]])
        adjusted_value = cvc.adjust_layer_ranks(three_values)
        unique_value = np.unique(adjusted_value)
        assert( (unique_value.size == 4) and \
                (unique_value[0] == 0) and \
                (unique_value[1] == 2) and \
                (unique_value[2] == 3) and \
                (unique_value[3] == 4))

        four_values = np.array([[1,2,0],[4,3,0]])
        adjusted_value = cvc.adjust_layer_ranks(four_values)
        unique_value = np.unique(adjusted_value)
        assert( (unique_value.size == 5) and \
                (unique_value[0] == 0) and \
                (unique_value[1] == 2) and \
                (unique_value[2] == 3) and \
                (unique_value[3] == 4) and \
                (unique_value[4] == 5))
        
        return True
        
       
    def test_combined_rank(self):
        def compute_combined_ranking(RankList):
            """Original equation that computes the combined habitat ranking.
                
                Input: RankList: a list of habitat ranks.
                
                Output: a combined habitat ranking. This equation is the verbose,
                unaltered python code used in the initial version of the model."""
            RankListMinus5 = [(5.0 - i) for i in RankList]
            SqRankList = [(i*i) for i in RankListMinus5]
            HabEq = \
            (1.5*max(RankListMinus5))**2+np.sum(SqRankList)-(max(RankListMinus5))**2
            rankValue = 4.8-0.5*((HabEq)**0.5)
            return rankValue

        # A few constants:
        kelp            = 4
        seagrass        = 4
        low_dune        = 3
        high_dune       = 2
        marsh           = 2
        coral           = 1
        mangrove        = 1
        coastal_forest  = 1 # If set to rank 3, we recover table in appendix B

        habitats = [[kelp],
                    [seagrass],
                    [seagrass, kelp],
                    [low_dune],
                    [coastal_forest],
                    [coastal_forest, kelp],
                    [low_dune, kelp],
                    [coastal_forest, seagrass],
                    [low_dune, seagrass],
                    [coastal_forest, kelp, seagrass],
                    [low_dune, kelp, seagrass],
                    [low_dune, coastal_forest],
                    [low_dune, coastal_forest, kelp],
                    [low_dune, coastal_forest, seagrass],
                    [low_dune, coastal_forest, kelp, seagrass],
                    [high_dune],
                    [marsh],
                    [high_dune, kelp],
                    [marsh, kelp],
                    [high_dune, seagrass],
                    [marsh, seagrass],
                    [high_dune, kelp, seagrass],
                    [high_dune, coastal_forest],
                    [high_dune, kelp, coastal_forest],
                    [marsh, coastal_forest, kelp],
                    [high_dune, seagrass, coastal_forest],
                    [marsh, coastal_forest, seagrass],
                    [high_dune, seagrass, kelp, coastal_forest],
                    [marsh, coastal_forest, kelp, seagrass],
                    [coral],
                    [mangrove],
                    [coral, seagrass],
                    [mangrove, seagrass],
                    [coral, coastal_forest],
                    [coral, low_dune],
                    [mangrove, seagrass, coastal_forest],
                    [coral, seagrass, coastal_forest],
                    [coral, seagrass, low_dune],
                    [coral, high_dune],
                    [coral, marsh],
                    [coral, seagrass, high_dune],
                    [coral, seagrass, marsh],
                    [coral, seagrass, low_dune, coastal_forest],
                    [mangrove, coral],
                    [coral, seagrass, high_dune, coastal_forest],
                    [mangrove, coral, seagrass],
                    [mangrove, coral, seagrass, coastal_forest]]
        

        ranking = np.array([compute_combined_ranking(np.array(habitats[i])) \
                            for i in range(len(habitats))])
        result = np.array([ cvc.combined_rank(np.array(habitats[i])) \
                            for i in range(len(habitats))])
        agreement = (result - ranking) < 0.001

        assert agreement.all()

    # TODO: load regression data from appropriate directory!!!!
    def test_detect_shore(self):
        """ test shore detection.
        
            inputs: none
            
            succeeds if the computed shore from the test raster is identical to
            the sample shore from the regression land file."""
        # Load regression shore data
        shore_raster_uri = os.path.join(self.args['regression_data_directory'], \
            'shore.tif')
        ds = gdal.Open(shore_raster_uri)
        band = ds.GetRasterBand(1)
        regression_shore = band.ReadAsArray()
        # Load AOI
        aoi_raster_uri = os.path.join(self.args['regression_data_directory'], \
            'aoi.tif')
        aoi_raster = gdal.Open(aoi_raster_uri)
        aoi_band = aoi_raster.GetRasterBand(1)
        aoi_array = aoi_band.ReadAsArray()

        # No sea, no shore:
        no_sea = np.ones_like(regression_shore)
        shore = cvc.detect_shore(no_sea, aoi_array, -1.)
        self.assertEquals(np.sum(shore), 0)

        # No land, no shore:
        no_land = np.zeros_like(regression_shore)
        shore = cvc.detect_shore(no_sea, aoi_array, -1)
        self.assertEquals(np.sum(shore), 0)

        # Cross-checking with a regression file:
        landmass_uri = os.path.join(self.args['regression_data_directory'], \
            'landmass.tif')
        landmass_raster = gdal.Open(landmass_uri)
        landmass_band = landmass_raster.GetRasterBand(1)
        landmass_array = landmass_band.ReadAsArray()
        landmass_array[aoi_array == 0] = -1.
        shore = cvc.detect_shore(landmass_array, aoi_array, 0.)
        computed_shore_uri = \
        os.path.join(self.args['regression_data_directory'], \
        'computed_shore.tif')
        shutil.copy(landmass_uri, computed_shore_uri)
        computed_shore_raster = gdal.Open(computed_shore_uri, gdal.GA_Update)
        computed_shore_raster.GetRasterBand(1).WriteArray(shore)
        computed_shore_raster = None

        self.assertEquals(np.sum(np.fabs(shore - regression_shore)), 0)


    def test_fetch_vectors(self):
        """ Test the fetch direction according to Greg Guannel's explanation.
            Each fetch sector has an angle associated to it, but extracting 
            the vector direction in the raster array coordinates 
            is not trivial. The convention, in Greg's terms:
                -angle   0 degrees: the wind blows from north, towards south.
                -angle  90 degrees: the wind blows from east towards west.
                -angle 180 degrees: the wind blows from south towards north.
                -angle 270 degrees: the wind blows from west towards east.
                
            The fetch rays start from the shore and travel seaward (traveling
            TO), whereas the wind blows from the ocean towards the coast
            (blowing FROM). So here is the angle convention for the fetch rays:
                -angle   0 degrees: fetch rays travel from south towards north
                -angle  90 degrees: fetch rays travel from west to east
                -angle 180 degrees: fetch rays travel from north to south
                -angle 270 degrees: fetch rays travel from east to west
                
            The raster coordinates are indexed as [row, column] where the row 
            number increases going down, and the column index increases going
            right. For a raster where north is up, the vector coordinates that
            correspond to the compass rose are:
                -angle   0 degrees: north [-1,  0]
                -angle  90 degrees: east  [ 0,  1]
                -angle 180 degrees: south [ 1,  0]
                -angle 270 degrees: west  [ 0, -1]
            which is also the fetch directions."""
        angles = [0., math.pi / 2., math.pi, 3. * math.pi / 2.]
        result = np.array([[-1., 0.], [0., 1], [1., 0.], [0., -1.]])

        vectors = cvc.fetch_vectors(angles)

        self.assertEquals(np.sum(np.fabs(vectors - result)), 0.)

    def test_compute_fetch(self):
        """ Test fetch computation with random directions, max distances and
        termination conditions.
        
            args['fetch_test_raster']: raster filename used to test the
                fetch algorithm.
            args['fetch_expected_result']: comma-separated filename that
                contains the expected result of the fetch calculation.
                
            succeeds if computing fetch over 'fetch_test_raster' yields the
                same result as in 'fetch_expected_result', fails otherwise."""
        message = \
        'Testing fetch algorithm distances against hand-designed shoreline'
        LOGGER.debug(message)
        # --------------------------------------------------------------------
        # Simple test cases that can be computed by hand:
        #   1- Minimalistic: only 1 shore point, 0 fetch distances
        #   2- Non-square land raster, variable fetch distances (0 or 1)
        #   3- Variable fetch distances beyond 1
        #   4- Minimalistic island (1 point)
        #   5- Small non-trivial island (L-shaped)
        # --------------------------------------------------------------------
        d_max = 4 
        cell_size = 1
        rays_per_sector = 1

        #   1- Minimalistic: no shore points, 2.5 fetch distance
        # Land is 1, water is 0
        # We're initializing a square area of water to test the fetch algorith:
        #     
        #    xxxxx
        #    x   x
        #    x . x
        #    x   x
        #    xxxxx
        #
        #   When we cast rays from the center point '.' outwards (towards the
        #   'x'), the length of the fetch rays depend on their direction
        #   (unlike a circle where they are all equal). We want to take the
        #   angles 'a' from 0 to 2PI and come up with a series of angles 'A' 
        #   such that cos(A) times a constant will give us
        #   the length of a ray cast at the angle 'a'. So we're looking for a
        #   transformation 'T' such that A = T(a). If we take as
        #   convention that the up direction is zero radians, and right is
        #   PI/4 rads, then the length of the rays increase from 0 to PI/4,
        #   then decrease from PI/4 to PI/2, and increase again. This
        #   increase/decrease pattern is periodic and repeats 4 times across
        #   all directions (interval [0, 2PI]).
        #       
        #    xx|xx
        #    x | x
        #    --.--
        #    x | x
        #    xx|xx
        #
        #   So we can 'chop' the big interval [0, 2PI] into 4 smaller intervals
        #   between 0 and PI/2 using the modulus operator (%):
        #   a1 = a % (PI/2) # 'a' is the angles in [0, 2PI]
        #
        #   Also, there's a symmetry around PI/4: the ray lengths at 0 and PI/2 
        #   rads are identical, at PI/8 and 3PI/8 also, and for every other
        #   pair of angles that are symmetric around PI/4.
        #
        #      0 PI/8 PI/4
        #      |  /  /
        #      | |  /
        #      | / /
        #      |/ / _3PI/8
        #    xxxxx /
        #    x | x-
        #    x .-x---0
        #    x   x
        #    xxxxx
        #
        #   We can use the absolute value to get this symmetry by making the
        #   interval negative in the first half, and positive in the second
        #   half: [0, PI/2] - PI/4 = [-PI/4, PI/4]
        #   abs([-PI/4, PI/4]) = [PI/4, 0] U [0, PI/4]
        #
        #   We're off by PI/4, because we want to start the interval at 0, not
        #   PI/4, so we subtract PI/4 from the original angle:
        #   A = | ((a - PI/4) % PI/2) - PI/4|, or in pseudo-code notation:
        #   A = abs(mod(a - PI/4, PI/2) - PI/4) 
        #
        land_raster = np.zeros((5, 5)).astype('float')
        # Shore is water bordered by a land cell.
        shore_points = (np.array([2]), np.array([2]))
        # Bathymetry is set to zero, since we don't use this information yet
        bathymetry = np.ones_like(land_raster) * -2.

        # Span in radians of a sector
        sectors_angular_span = 2. * math.pi / 16
        # Lowest bound for sector zero
        sectors_min_angle = -sectors_angular_span / 2.
        # Total number of rays to cast
        ray_count = rays_per_sector * 16
        # Angle between consecutive rays (radians)
        angle_increment = sectors_angular_span / rays_per_sector
        # Increasing angles from 0 to just before 2 PI
        angles = np.array(range(ray_count)) * math.pi * 2. / ray_count
        # Adjust angles so that rays are equally distributed around the
        # sector's major angle
        angles = angles + sectors_min_angle + angle_increment / 2.
        # Reshape the agles matrix so that a row corresponds to a sector and a
        # column is the n-th ray in a sector
        angles = np.reshape(angles, (16, rays_per_sector))
        #print('angles', angles)
        # Compute the angles so that their length trace the shape of a square
        angles = np.absolute(np.mod(angles+math.pi/4.,math.pi/2.)-math.pi/4.)
        #print('|PI/4 - (a+PI/4) % PI/2|', angles)
        # Correction weights, 1st step: angles
        weights = np.copy(angles[0])
        # Correction weights, 3rd step: cosines
        weights = np.cos(weights)
        #print('weights', weights)
        # Compute lengths
        lengths = 2.5 / np.cos(angles)
        #print('lengths', lengths)
        # Compute weighted lengths
        lengths = lengths * weights
        #print('weighted lengths', lengths)
        # The solution is the row-wise average
        solution = np.average(lengths, axis=1)
        
        # compute the fetch
        distances = cvc.compute_fetch(land_raster, rays_per_sector, d_max, 
            cell_size, shore_points, bathymetry, -1)[0].values()[0]
        # Test fetch against solution
        max_error = 10e-8
        error = np.absolute(np.sum(solution - distances))
        message = 'Cumulative error is too high (' + str(error) + \
            '), max error is ' + str(max_error) + '.'
        assert error < max_error, message 

        # Testing d_max:
        d_max = 3.
        distances = cvc.compute_fetch(land_raster, rays_per_sector, d_max, 
            cell_size, shore_points, bathymetry, -1)[0].values()[0]
        message = 'Minimal test: maximum computed value (' + \
        str(np.amax(distances)) + ') is beyond the maximum fetch (' + \
        str(d_max) + ').'
        assert np.amax(distances) <= d_max, message 

        # Test with added pixels in the North direction, which is angle zero.
        # If test passes, it validates 2 things at a time: the rays successfully
        # stop on land, and the up direction is effectively angle 0
        land_raster[0, 2] = 1
        distances = cvc.compute_fetch(land_raster, rays_per_sector, 4, 
            cell_size, shore_points, bathymetry, -1)[0].values()[0]
        solution[0] -= 1
        error = np.absolute(np.sum(solution - distances))
        message = 'North pixel test: cumulative error is too high (' + \
            str(error) + '), max error is ' + str(max_error) + '.'
        assert error < max_error, message 
        # Test with added pixel in the east direction to see if it corresponds
        # to the angle PI/2 rad:
        land_raster[0, 2] = 0
        land_raster[2, 4] = 1
        distances = cvc.compute_fetch(land_raster, rays_per_sector, 4, 
            cell_size, shore_points, bathymetry, -1)[0].values()[0]
        solution[0] += 1
        solution[4] -= 1
        error = np.absolute(np.sum(solution - distances))
        message = 'East pixel test: cumulative error is too high (' + \
            str(error) + '), max error is ' + str(max_error) + '.'
        assert error < max_error, message 

        # TODO: Test with regression data
        # TODO: Test distances
        return True 

    def tare_down(self):
        """ Clean up code."""
        # Do nothing for now 
        pass
